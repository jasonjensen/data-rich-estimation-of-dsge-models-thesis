"""
    get_dist_R_Î›(X, Ï, S::KeyedArray, sâ‚€=0.001, vâ‚€=3, ğš²â‚€=zeros(size(S, 1)), ğŒâ‚€=I(size(S, 1)), c=1.0; constraint=:none, state_index=0)

Calculate the conditional posterior distributions for R (measurement error variance) and Î› (observation matrix coefficients).

# Arguments
- `X`: Time series of observed data.
- `Ï`: Autocorrelation coefficient for detrending.
- `S::KeyedArray`: Time series of states.
- `sâ‚€=0.001`: Prior scale for R.
- `vâ‚€=3`: Prior degrees of freedom for R.
- `ğš²â‚€=zeros(size(S, 1))`: Prior mean for Î›.
- `ğŒâ‚€=I(size(S, 1))`: Prior precision for Î›.
- `constraint=:none`: Type of constraint on Î› (:none, :one, :four, :any, :anyfour).
- `state_index=0`: Index of the state variable if a constraint is applied.

# Returns
- `R_dist`: InverseGamma distribution for R.
- `Î›_dist`: Normal or MvNormal distribution for Î›.
"""
function get_dist_R_Î›(X, Ï, S::KeyedArray, sâ‚€=0.001, vâ‚€=3, ğš²â‚€=zeros(size(S, 1)), ğŒâ‚€=I(size(S, 1)); constraint=:none, state_index=0)
   
    Xáµ¡ =  X[2:end] - Ï*X[1:end-1] # discard first obs
    Sáµ¡     = Matrix(S')[2:end, :] .- Ï .* Matrix(S')[1:end-1, :]
    
    if constraint âˆˆ (:one, :four, :any, :anyfour)
        Sáµ¡ = reshape(Sáµ¡[:,state_index], (size(Sáµ¡,1),1))
        ğŒâ‚€ = reshape([1.0], (1,1))
    end
    
    nObs = size(Sáµ¡,1)
    
    ğš²fit = nothing
    ğš²hat = zeros(size(S, 1))

    if constraint == :none
        ğš²fit = lm(Sáµ¡, Xáµ¡)
        ğš²hat = coef(ğš²fit)
    elseif constraint == :one
        ğš²hat = [1.0]
        ğš²â‚€ = [1]
    elseif constraint == :four
        ğš²hat = [4.0]
        ğš²â‚€ = [4]
    elseif constraint == :any
        ğš²fit = lm(Sáµ¡, Xáµ¡)
        ğš²hat = [coef(ğš²fit)[1]]
        ğš²â‚€ = [1]
    elseif constraint == :anyfour
        ğš²fit = lm(Sáµ¡, Xáµ¡)
        ğš²hat = [coef(ğš²fit)[1]]
        ğš²â‚€ = [4]
    end


    ğŒbar = ğŒâ‚€ + (Sáµ¡' * Sáµ¡)
    ğš²bar = inv(ğŒbar) * ((Sáµ¡' * Sáµ¡)*ğš²hat + ğŒâ‚€* ğš²â‚€)
    Xáµ€X = Xáµ¡' * Xáµ¡
    
    if Xáµ€X isa Matrix{Float64}
        sâ‚€ =  reshape([sâ‚€], (1,1))
    end
    
    if constraint == :none
        sbar = sâ‚€ + 0.5*(Xáµ€X - ğš²bar' * (ğŒâ‚€ + (Sáµ¡' * Sáµ¡)) * ğš²bar + ğš²â‚€' * ğŒâ‚€ * ğš²â‚€)
        sbar = first(sbar)
    else
        sbar = first(sâ‚€) + 0.5*((Xáµ¡ - Sáµ¡ * ğš²hat)' * (Xáµ¡ - Sáµ¡ * ğš²hat))
    end
    vbar = vâ‚€ + (nObs - 1)/2

    # InverseGamma(Î±::shape, Î¸::Scale) ; shape controls tail heaviness, scale controls spread
    # The shape parameter is tied to degrees of freedom
    R_dist = Distributions.InverseGamma(vbar, sbar)
    
    Î›_dist = nothing
    if constraint âˆˆ (:one, :four, :any, :anyfour)
        Î›_dist = Distributions.Normal(ğš²bar[1], sqrt.(inv(ğŒbar[1])))
    else
        ğŒbarâ»Â¹ = isposdef(ğŒbar) ? inv(ğŒbar) : pinv(ğŒbar)
        if !isposdef(ğŒbarâ»Â¹)
            ğŒbarâ»Â¹ = make_psd(ğŒbarâ»Â¹)
        end
        Î›_dist = Distributions.MvNormal(ğš²bar, ğŒbarâ»Â¹)
    end
    
    return R_dist, Î›_dist
end

"""
    get_dist_Ïˆ(X, S, Î›â‚–, Râ‚–â‚–, Ïâ‚€, ÏƒÂ², c=1.0)

Calculate the conditional posterior distribution for Ïˆ (autocorrelation of measurement error).

# Arguments
- `X`: Time series of observed data.
- `S`: Time series of states.
- `Î›â‚–`: Observation matrix coefficient.
- `Râ‚–â‚–`: Measurement error variance.
- `Ïâ‚€`: Prior mean for Ïˆ.
- `ÏƒÂ²`: Prior variance for Ïˆ.

# Returns
- `Ïˆ_dist`: Truncated Normal distribution for Ïˆ.
"""
function get_dist_Ïˆ(X, S, Î›â‚–, Râ‚–â‚–, Ïâ‚€, ÏƒÂ²)
    
    eâ‚– = X - Matrix(S'[1:end-1,:]) * Î›â‚–
    
    ğ›™hatâ‚–â‚– = inv(eâ‚–[1:end-1]' * eâ‚–[1:end-1]) * eâ‚–[1:end-1]' * eâ‚–[2:end]

    Vbar = inv(inv(Râ‚–â‚– * inv(eâ‚–[1:end-1]' * eâ‚–[1:end-1])) +  inv(ÏƒÂ²))
    ğ›™bar = Vbar * (inv(Râ‚–â‚– * inv(eâ‚–[1:end-1]' * eâ‚–[1:end-1])) * ğ›™hatâ‚–â‚– + inv(ÏƒÂ²)*Ïâ‚€)
    
    Ïˆ_dist = truncated(Distributions.Normal(ğ›™bar, sqrt(Vbar)), 0.0 + eps(Float64), 1.0-eps(Float64))

    return Ïˆ_dist
end

"""
     draw_Ïˆ(X, S, Î›â‚–, Râ‚–â‚–, Ïâ‚€, ÏƒÂ², c=1.0)

Sample Ïˆ (autocorrelation of measurement error) from its conditional posterior distribution.

# Arguments
- `X`: Time series of observed data.
- `S`: Time series of states.
- `Î›â‚–`: Observation matrix coefficient.
- `Râ‚–â‚–`: Measurement error variance.
- `Ïâ‚€`: Prior mean for Ïˆ.
- `ÏƒÂ²`: Prior variance for Ïˆ.

# Returns
- `Ïˆ_draw`: A draw for Ïˆ.
- `loglikÏˆ`: Log-likelihood of the draw.
"""
function draw_Ïˆ(X, S, Î›â‚–, Râ‚–â‚–, Ïâ‚€, ÏƒÂ²)
    Ïˆ_dist = get_dist_Ïˆ(X, S, Î›â‚–, Râ‚–â‚–, Ïâ‚€, ÏƒÂ²)
    Ïˆ_draw = rand(Ïˆ_dist)
    Ïˆ_prior = Distributions.Normal(0,1)
    loglikÏˆ = logpdf(Ïˆ_prior, Ïˆ_draw)
    return Ïˆ_draw, loglikÏˆ
end

"""
    get_initial_Î“(S::KeyedArray, data::Workspace, Î›_constraints=Dict{String, Pair{Symbol,Symbol}}())

Helper function to call `get_initial_Î“` with data from a Workspace.

# Arguments
- `S::KeyedArray`: KeyedArray of states.
- `data::Workspace`: Workspace object containing data.
- `Î›_constraints=Dict{String, Pair{Symbol,Symbol}}()`: Dictionary of constraints for Î›.

# Returns
- Tuple: Contains initial estimates for R, Î›, ğ›™, and ğ›™_Ïƒ.
"""
function get_initial_Î“(S::KeyedArray, data::Workspace, Î›_constraints=Dict{String, Pair{Symbol,Symbol}}())
    return get_initial_Î“(data.X, S, data.nVars, data.nStates, data.core_series, data.core_series_modelsyms, Î›_constraints)
end

# TODO: clean up get_initial_Î“ vs get_initial_Î“_old
"""
    get_initial_Î“(X::DataFrame, S::KeyedArray, nVars::Int64=size(X,2), nStates::Int64=size(S,1), core_series=Vector{String}(), core_series_modelsyms=Vector{Symbol}(), Î›_constraints=Dict{String, Pair{Symbol,Symbol}}())

Calculate initial estimates for R, Î›, ğ›™, and ğ›™_Ïƒ.

This function iterates through the variables in `X`, calculates initial estimates for the measurement error variance (R),
observation matrix (Î›), and autocorrelation of measurement error (ğ›™ and ğ›™_Ïƒ) for each variable.
It uses `get_initial_Î“_old` for the main calculations and then refines R and Î› using `get_dist_R_Î›`.

# Arguments
- `X::DataFrame`: DataFrame of observed data.
- `S::KeyedArray`: KeyedArray of states.
- `nVars::Int64`: Number of variables.
- `nStates::Int64`: Number of states.
- `core_series=Vector{String}()`: Vector of core series names.
- `core_series_modelsyms=Vector{Symbol}()`: Vector of core series model symbols.
- `Î›_constraints=Dict{String, Pair{Symbol,Symbol}}()`: Dictionary of constraints for Î›.

# Returns
- `R`: Initial estimate for the measurement error variance matrix.
- `Î›`: Initial estimate for the observation matrix.
- `ğ›™`: Initial estimate for the autocorrelation of measurement error matrix.
- `ğ›™_Ïƒ`: Initial estimate for the standard deviation of ğ›™.
"""
function get_initial_Î“(X::DataFrame, S::KeyedArray, nVars::Int64=size(X,2), nStates::Int64=size(S,1), core_series=Vector{String}(), core_series_modelsyms=Vector{Symbol}(), Î›_constraints=Dict{String, Pair{Symbol,Symbol}}())
    R, Î›, ğ›™, ğ›™_Ïƒ = get_initial_Î“_old(X,S,nVars,nStates, core_series, core_series_modelsyms, Î›_constraints)

    # Set Psi to very low for core series
    for (i, key) in enumerate(names(X))
        # @show key
        state_var, constraint = first(S.Variable) => :none
        state_index = 1
        if haskey(Î›_constraints, key)
            state_var, constraint = Î›_constraints[key]
            state_index = findfirst(x -> x == state_var, S.Variable)
        end
        if constraint == :one || constraint == :four
            ğ›™[i,i] = ğ›™[i,i] * 1e-6
        end

        
        R_dist, Î›_dist = get_dist_R_Î›(X[!, key], ğ›™[i,i], S; constraint=constraint, state_index=state_index)
        R[i,i] = Distributions.mean(R_dist)
        if constraint == :none
            Î›_dist_alt = Distributions.MvNormal(Î›_dist.Î¼, sqrt(R[i,i] .* Î›_dist.Î£)) 
            Î›[i,:] = Distributions.mean(Î›_dist_alt)
        else
            Î›_dist_alt = Distributions.Normal(Î›_dist.Î¼, sqrt(R[i,i]) .* Î›_dist.Ïƒ) 
            Î›[i,:] .= 0
            Î›[i,state_index] = Distributions.mean(Î›_dist_alt)
        end
    end
    return (R, Î›, ğ›™, ğ›™_Ïƒ)
end

"""
    get_initial_Î“_old(X::DataFrame, S::KeyedArray, nVars::Int64=size(X,2), nStates::Int64=size(S,1), core_series=Vector{String}(), core_series_modelsyms=Vector{Symbol}(), Î›_constraints=Dict{String, Pair{Symbol,Symbol}}())

Calculate initial estimates for R, Î›, ğ›™, and ğ›™_Ïƒ using ordinary least squares (OLS).

This function iterates through each variable in `X` and performs the following steps:
1. Extracts the relevant state variables based on constraints.
2. Fits an OLS model to estimate the relationship between the variable and states.
3. Calculates the autocorrelation (Ï) of the residuals from the initial fit.
4. Refits the OLS model using GLS-transformed data (correcting for autocorrelation).
5. Stores the estimated coefficients (Î›_Î¼), standard errors (Î›_Ïƒ), variance of residuals (R_Î˜), autocorrelation (ğ›™_Î¼), and standard error of autocorrelation (ğ›™_Ïƒ).

# Arguments
- `X::DataFrame`: DataFrame of observed data.
- `S::KeyedArray`: KeyedArray of states.
- `nVars::Int64`: Number of variables.
- `nStates::Int64`: Number of states.
- `core_series=Vector{String}()`: Vector of core series names (unused in current implementation, but kept for compatibility).
- `core_series_modelsyms=Vector{Symbol}()`: Vector of core series model symbols (unused in current implementation, but kept for compatibility).
- `Î›_constraints=Dict{String, Pair{Symbol,Symbol}}()`: Dictionary of constraints for Î›. 

# Returns
- `R_Î˜`: Initial estimate for the measurement error variance matrix.
- `Î›_Î¼`: Initial estimate for the observation matrix (mean coefficients).
- `ğ›™_Î¼`: Initial estimate for the autocorrelation of measurement error matrix.
- `ğ›™_Ïƒ`: Initial estimate for the standard deviation of ğ›™_Î¼.
"""
function get_initial_Î“_old(X::DataFrame, S::KeyedArray, nVars::Int64=size(X,2), nStates::Int64=size(S,1), core_series=Vector{String}(), core_series_modelsyms=Vector{Symbol}(), Î›_constraints=Dict{String, Pair{Symbol,Symbol}}())
    Î›_Î¼ = zeros(nVars, nStates)
    Î›_Ïƒ = zeros(nVars, nStates)
    Î›_vcov = zeros(nVars, nStates, nStates)
    R_Î˜ = Diagonal(zeros(nVars,nVars))
    ğ›™_Î¼= Diagonal(zeros(nVars, nVars))
    ğ›™_Ïƒ= Diagonal(zeros(nVars, nVars))

    for (i, key) in enumerate(names(X))
        
        # Retrieve constraint
        state_var, constraint = first(S.Variable) => :none
        state_index = 1
        if haskey(Î›_constraints, key)
            state_var, constraint = Î›_constraints[key]
            state_index = findfirst(x -> x == state_var, S.Variable)
        end
        

        # extract regression matrices
        # obs! no intercept
        _S = Matrix(S')
        
        Xâ‚– = X[2:end, key] # discard first obs
        
       
        # adjust regression matrices
        if constraint âˆˆ (:any, :one, :four, :anyfour)
            _S = _S[:,state_index:state_index]
        end
        if size(_S,1) !== size(Xâ‚–,1)
            _S = _S[end-size(Xâ‚–,1)+1:end, :]
        end
        
        initial_fit = lm(_S, Xâ‚–)
        
        # autocorrelation of errors
        resid = residuals(initial_fit)
        if constraint == :one
            resid = Xâ‚– - _S
        elseif constraint == :four
            resid = Xâ‚– - (4 * _S)
        end
        Ï_fit = lm(reshape(resid[1:end-1], (length(resid)-1, 1)), resid[2:end])
        Ï = Ï_fit.pp.beta0[1]
        ğ›™_Î¼[i,i] = Ï
        ğ›™_Ïƒ[i,i] = stderror(Ï_fit)[1]
        
        
        # revised fit
        y_revised =  initial_fit.rr.y[2:end] - Ï*initial_fit.rr.y[1:end-1]
        # would need to add a const*(1-Ï) component if there is a constant.
        X_revised = initial_fit.pp.X[2:end, :] .- Ï .* initial_fit.pp.X[1:end-1, :]
        if constraint == :one || constraint == :four
            y_revised = _S[2:end] - Ï*_S[1:end-1]
            X_revised = Xâ‚–[2:end] - Ï*Xâ‚–[1:end-1]
            X_revised = reshape(X_revised, (length(X_revised), 1))
        end
        
        Î»_fit = lm(X_revised, y_revised)
        R_Î˜[i,i] = StatsBase.var(residuals(Î»_fit))

        if constraint == :none
            Î›_Î¼[i,:] = coef(Î»_fit)
            Î›_Ïƒ[i,:] = stderror(Î»_fit)
            Î›_vcov[i, :, :] = vcov(Î»_fit)
        elseif constraint == :one
            Î›_Î¼[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Ïƒ[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Î¼[i,state_index] = 1.0
        elseif constraint == :four
            Î›_Î¼[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Ïƒ[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Î¼[i,state_index] = 4.0
        elseif constraint == :any
            Î›_Î¼[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Ïƒ[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Î¼[i,state_index] = Ï_fit.pp.beta0[1]
            Î›_Ïƒ[i,state_index] = stderror(Î»_fit)[1]
        elseif constraint == :anyfour
            Î›_Î¼[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Ïƒ[i,:] = zeros(size(Î›_Î¼, 2))
            Î›_Î¼[i,state_index] = Ï_fit.pp.beta0[1]
            Î›_Ïƒ[i,state_index] = stderror(Î»_fit)[1]
        end
    end

    return R_Î˜, Î›_Î¼, ğ›™_Î¼, ğ›™_Ïƒ
end



"""
    draw_R_Î›(X, ğ›™_Î¼, S, c;  constraint=:none, state_index=0, var="")

Draw R and Î› from their conditional posterior distributions.

# Arguments
- `X`: Time series of observed data.
- `ğ›™_Î¼`: Mean of the autocorrelation of measurement error.
- `S`: Time series of states.
- `constraint=:none`: Type of constraint on Î› (:none, :one, :four, :any, :anyfour).
- `state_index=0`: Index of the state variable if a constraint is applied.
- `var=""`: Name of the variable (used for special rules for FedFunds and RINV).

# Returns
- `R_draw`: Draw of the measurement error variance.
- `Î›_draw`: Draw of the observation matrix coefficients.
- `0.0`: Placeholder for log-likelihood of ğ›™ (not calculated in this function).
- `0.0`: Placeholder for log-likelihood of ğ›™_Ïƒ (not calculated in this function).
"""
function draw_R_Î›(X, ğ›™_Î¼, S;  constraint=:none, state_index=0, var="")
   
    R_dist, Î›_dist = get_dist_R_Î›(X, ğ›™_Î¼, S, constraint=constraint, state_index=state_index)
    R_draw = 1.0 .* rand(R_dist)
    
    # special rules for FedFunds and RINV
    if var âˆˆ ("FedFunds",)
        while R_draw > 0.05
            vbar = R_dist.invd.Î± * 2
            sbar = R_dist.invd.Î¸ * 2
            R_dist = Distributions.InverseGamma((vbar+1)/2, 2/sbar)
            R_draw = rand(R_dist)
        end
    end
    if var == "RINV"
        while R_draw > 2.0
            vbar = R_dist.invd.Î± * 2
            sbar = R_dist.invd.Î¸ * 2
            R_dist = Distributions.InverseGamma((vbar+1)/2, 2/sbar)
            R_draw = rand(R_dist)
        end
    end
    
    # loglikR = logpdf(Distributions.InverseGamma(0.001,3), R_draw)
    
    Î›_draw = zeros(size(S,1))
    if constraint == :none
        Î›_dist_corrected = Distributions.MvNormal(Î›_dist.Î¼, R_draw .* Î›_dist.Î£)
        Î›_draw = rand(Î›_dist_corrected)
    else
        Î›_dist_corrected = Distributions.Normal(Î›_dist.Î¼, sqrt(R_draw) .* Î›_dist.Ïƒ) 
        Î›_draw[state_index] = rand(Î›_dist_corrected)
    end
    
    return R_draw, Î›_draw, 0.0, 0.0
end


"""
    draw_Î“(X::DataFrame, S, nVars, nStates, ğ›™_Î¼, ğ›™_Ïƒ, core_series=Vector{String}(), core_series_modelsyms=Vector{Symbol}(), Î›_constraints=Dict{String, Pair{Symbol,Symbol}}(), c=1.0, measurement_error=true, verbose=false)

Draw Î“ (Î›, ğ›™, R) from their conditional posterior distributions.

This function iterates through each variable in `X` and performs the following:
1. Draws R and Î› using `draw_R_Î›`.
2. Applies constraints to Î› if specified.
3. If `measurement_error` is true, samples ğ›™ using `draw_Ïˆ`.
4. Calculates the total log-likelihood for Î“.

# Arguments
- `X::DataFrame`: DataFrame of observed data.
- `S`: Time series of states.
- `nVars`: Number of variables.
- `nStates`: Number of states.
- `ğ›™_Î¼`: Mean of the prior for ğ›™.
- `ğ›™_Ïƒ`: Standard deviation of the prior for ğ›™.
- `core_series=Vector{String}()`: Vector of core series names.
- `core_series_modelsyms=Vector{Symbol}()`: Vector of core series model symbols.
- `Î›_constraints=Dict{String, Pair{Symbol,Symbol}}()`: Dictionary of constraints for Î›.
- `measurement_error=true`: Boolean indicating whether to model measurement error.
- `verbose=false`: Boolean indicating whether to print verbose output.
"""
function draw_Î“(X::DataFrame, S, nVars, nStates, ğ›™_Î¼, ğ›™_Ïƒ, core_series=Vector{String}(), core_series_modelsyms=Vector{Symbol}(), Î›_constraints=Dict{String, Pair{Symbol,Symbol}}(), measurement_error=true, verbose=false)
    local Î› = zeros(nVars, nStates)
    local R = Diagonal(zeros(nVars, nVars))
    local ğ›™= Diagonal(zeros(nVars, nVars))
    local loglikÎ› = zeros(nVars)
    local loglikR = zeros(nVars)
    local loglikÏˆ = zeros(nVars)

    for (i, key) in enumerate(names(X))
        constraint = :none
        state_index=0
        if haskey(Î›_constraints, key)
            state_var, constraint = Î›_constraints[key]
            state_index = findfirst(x -> x == state_var, S.Variable)
        end

        R[i,i], Î›[i,:], loglikR[i], loglikÎ›[i]  = draw_R_Î›(X[!, key], ğ›™_Î¼[i,i], S; constraint=constraint, state_index=state_index, var=key)
        
        if haskey(Î›_constraints, key)
            state_var, constraint = Î›_constraints[key]
            state_index = findfirst(x -> x == state_var, S.Variable)
            old_val =  Î›[i,state_index]
            Î›[i,:] = zeros(size(Î›, 2))
            if constraint == :one
                Î›[i,state_index] = 1.0
                loglikR[i] = 0
                loglikÎ›[i] = 0
            elseif constraint == :four
                Î›[i,state_index] = 4.0
                loglikR[i] = 0
                loglikÎ›[i] = 0
            elseif constraint âˆˆ (:any, :anyfour)
                Î›[i,state_index] = old_val
            end
        end

        if measurement_error
            ğ›™[i,i], loglikÏˆ[i] = draw_Ïˆ(X[2:end, key], S, Î›[i,:], R[i,i], ğ›™_Î¼[i,i], ğ›™_Ïƒ[i,i])
        end
    end
    
    loglikÎ“ = sum(loglikÎ›) + sum(loglikR) + sum(loglikÏˆ)
   
    if verbose
        println("==================")
        println("Î›: $(sum(loglikÎ›))")
        display(Î›)
        println("R: $(sum(loglikR))")
        display(R)
        println("Ïˆ: $(sum(loglikÏˆ))")
        display(ğ›™)
        println("==================")
    end
    
    if !measurement_error
        R = Diagonal(zeros(nVars, nVars))
        loglikÎ“ = 0 # simplifying assumption that Î› is fixed when measurement_error==false
    end


    return Î›, ğ›™, R, loglikÎ“
end

"""
    draw_Î“(S::KeyedArray, data::Workspace, ğ›™_Î¼::Diagonal, ğ›™_Ïƒ::Diagonal, Î›_constraints=Dict{String, Pair{Symbol,Symbol}}(), measurement_error=true, verbose=false)

Draw Î“ (Î›, ğ›™, R) from their conditional posterior distributions using data from a Workspace.

# Arguments
- `S`: Time series of states.
- `data`: Workspace containing X and other information.
- `ğ›™_Î¼`: Mean of the prior for ğ›™.
- `ğ›™_Ïƒ`: Standard deviation of the prior for ğ›™.
- `Î›_constraints=Dict{String, Pair{Symbol,Symbol}}()`: Dictionary of constraints for Î›.
- `measurement_error=true`: Boolean indicating whether to model measurement error.
- `verbose=false`: Boolean indicating whether to print verbose output.

# Returns
- `R`: Draw of the measurement error variance matrix.
- `Î›`: Draw of the observation matrix.
- `ğ›™`: Draw of the autocorrelation of measurement error matrix.
- `ğ›™_Ïƒ`: Draw of the standard deviation of ğ›™.
- `loglik`: Total log-likelihood for Î“.
"""
function draw_Î“(S::KeyedArray, data::Workspace, ğ›™_Î¼::Diagonal, ğ›™_Ïƒ::Diagonal, Î›_constraints=Dict{String, Pair{Symbol,Symbol}}(), measurement_error=true, verbose=false)
    return draw_Î“(data.X, S, data.nVars, data.nStates, ğ›™_Î¼, ğ›™_Ïƒ, data.core_series, data.core_series_modelsyms, Î›_constraints, measurement_error, verbose)
end


"""
    perturb_Î¸(m, Î¸prev, Î£â»Â¹, c; fixed_parameters=Vector{Symbol}())

Perturb the previous parameter vector `Î¸prev` and evaluate the prior likelihood.

# Arguments
- `m`: The model object.
- `Î¸prev`: The previous parameter vector.
- `Î£â»Â¹`: Inverse of the covariance matrix for the proposal distribution.
- `c`: Scaling factor for the proposal distribution.
- `fixed_parameters=Vector{Symbol}()`: A vector of symbols indicating parameters that should not be perturbed.

# Returns
- `Î¸`: The new (potentially perturbed) parameter vector.
- `total_loglik_new`: The log-likelihood of the new parameters under their priors.
- `ğ’mat`: The new steady-state solution if the model solves with the new parameters.
- `true` if the model solves with the new parameters, `false` otherwise.
"""
function perturb_Î¸(m, Î¸prev, Î£â»Â¹, c; fixed_parameters=Vector{Symbol}())
    dist = MvNormal(Î¸prev, c * Î£â»Â¹)
    perturbations = rand(dist)

    Î¸ = copy(Î¸prev)
    
    total_loglik_new = 0.0
    for (i, param, new_value, prev_value) in zip(1:length(m.parameters), m.parameters, perturbations, Î¸prev)
        if param âˆ‰ fixed_parameters
            Î¸[i] = clamp_Î¸(Val(Symbol(m.model_name)), Val(param), new_value)
            if Î¸[i] != new_value 
                return (Î¸prev, 0, nothing, false)
            end
        end
        
        # compute loglik
        if param âˆ‰ fixed_parameters
            loglik = logpdf(
                prior_Î¸(Val(Symbol(m.model_name)), Val(param)), 
                Î¸[i]
            )
            total_loglik_new += loglik
        end
    end

    # make sure it works
    sol_guess = copy(m.solution.perturbation.qme_solution)
    TT, SS_and_pars, ğ’mat, state, solved = MacroModelling.get_relevant_steady_state_and_state_update(Val(:first_order), Î¸, m)
    if !solved
        m.solution.perturbation.qme_solution = copy(sol_guess)
        return Î¸prev, 0, nothing, false
    end

    # total_loglik_new = sum(logpdf(dist, perturbations))
    return Î¸, total_loglik_new, ğ’mat, true
end



